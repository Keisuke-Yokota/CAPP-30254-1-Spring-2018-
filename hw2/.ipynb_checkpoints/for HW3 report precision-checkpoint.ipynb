{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Analysis\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Analysis.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Analysis.fill_na(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Generate feature/predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_df, bins = Analysis.discretize(df.iloc[:, 6], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -1794.06,  299010.  ,  598020.  ,  897030.  , 1196040.  ,\n",
       "       1495050.  , 1794060.  ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    41010\n",
       "1        3\n",
       "2        2\n",
       "5        1\n",
       "Name: MonthlyIncome, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PersonID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99012</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99023</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99027</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99033</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99044</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99048</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99056</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99058</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99062</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99104</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99105</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99193</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99206</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99217</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99218</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99233</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99238</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99271</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99284</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123505</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123523</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123529</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123532</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123538</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123540</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123541</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123561</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123597</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123615</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123628</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123641</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123647</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123650</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123654</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123657</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123658</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123660</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123661</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123664</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123667</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123679</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123689</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123714</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123722</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123729</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123730</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123739</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123753</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41016 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1  2  5\n",
       "PersonID         \n",
       "98976     0  0  0\n",
       "98991     0  0  0\n",
       "99012     0  0  0\n",
       "99023     0  0  0\n",
       "99027     0  0  0\n",
       "99033     0  0  0\n",
       "99044     0  0  0\n",
       "99048     0  0  0\n",
       "99056     0  0  0\n",
       "99058     0  0  0\n",
       "99062     0  0  0\n",
       "99104     0  0  0\n",
       "99105     0  0  0\n",
       "99145     0  0  0\n",
       "99147     0  0  0\n",
       "99176     0  0  0\n",
       "99193     0  0  0\n",
       "99200     0  0  0\n",
       "99206     0  0  0\n",
       "99217     0  0  0\n",
       "99218     0  0  0\n",
       "99224     0  0  0\n",
       "99233     0  0  0\n",
       "99238     0  0  0\n",
       "99246     0  0  0\n",
       "99249     0  0  0\n",
       "99262     0  0  0\n",
       "99267     0  0  0\n",
       "99271     0  0  0\n",
       "99284     0  0  0\n",
       "...      .. .. ..\n",
       "123505    0  0  0\n",
       "123523    0  0  0\n",
       "123529    0  0  0\n",
       "123532    0  0  0\n",
       "123538    0  0  0\n",
       "123540    0  0  0\n",
       "123541    0  0  0\n",
       "123561    0  0  0\n",
       "123597    0  0  0\n",
       "123615    0  0  0\n",
       "123628    0  0  0\n",
       "123641    0  0  0\n",
       "123647    0  0  0\n",
       "123650    0  0  0\n",
       "123654    0  0  0\n",
       "123657    0  0  0\n",
       "123658    0  0  0\n",
       "123660    0  0  0\n",
       "123661    0  0  0\n",
       "123664    0  0  0\n",
       "123667    0  0  0\n",
       "123679    0  0  0\n",
       "123687    0  0  0\n",
       "123689    0  0  0\n",
       "123714    0  0  0\n",
       "123722    0  0  0\n",
       "123729    0  0  0\n",
       "123730    0  0  0\n",
       "123739    0  0  0\n",
       "123753    0  0  0\n",
       "\n",
       "[41016 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analysis.dumminize(cut_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Build Classifier\n",
    "# 6 Evaluate Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9869319290033158\n",
      "accuracy score: 0.987\n",
      "precison score: 0.995\n",
      "recall score: 0.925\n",
      "Confusion matrix:\n",
      "[[17146    16]\n",
      " [  252  3094]]\n",
      "f1 score: 0.958\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a121d8d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "Y = df.iloc[:, 0]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=0)\n",
    "Analysis.random_tree(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = ['accuracy', 'precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "BAG = BaggingClassifier()\n",
    "AB = AdaBoostClassifier()\n",
    "SVM = SVC()\n",
    "clfs = [LR,KNN,DT,RF,BAG,AB,SVM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_grid = { \n",
    "    RF:{'n_estimators': [1,10,100,1000,10000], 'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10]},\n",
    "    LR: { 'penalty': ['l1','l2'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1,10]},\n",
    "    AB: { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "    DT: {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100], 'max_features': [None, 'sqrt','log2'],'min_samples_split': [2,5,10]},\n",
    "    SVM :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear', 'rbf']},\n",
    "    KNN :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']},\n",
    "    BAG :{'n_estimators': [1,5,10,25,50,100],'max_features': [1,2,5,10]}     \n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_grid = { \n",
    "    RF:{'n_estimators': [100, 10000], 'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10]},\n",
    "    LR: { 'penalty': ['l1','l2'], 'C': [0.1,1,10]},\n",
    "    AB: { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1000,10000]},\n",
    "    DT: {'criterion': [ 'entropy'], 'max_depth': [5,50], 'max_features': [None,'sqrt','log2'],'min_samples_split': [2,10]},\n",
    "    SVM :{'C' :[0.01,0.1,1,10],'kernel':[ 'rbf']},\n",
    "    KNN :{'n_neighbors': [100, 10000],'weights': ['distance'],'algorithm': ['auto']},\n",
    "    BAG :{'n_estimators': [100, 10000],'max_features': [2,10]}     \n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'precision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.760 (+/- 0.013) for {'C': 0.1, 'penalty': 'l1'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.86      0.02      0.03      3274\n",
      "\n",
      "avg / total       0.85      0.84      0.77     20508\n",
      "\n",
      "[[17226     8]\n",
      " [ 3224    50]]\n",
      "0.805 (+/- 0.052) for {'C': 0.1, 'penalty': 'l2'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.86      0.02      0.03      3274\n",
      "\n",
      "avg / total       0.85      0.84      0.77     20508\n",
      "\n",
      "[[17226     8]\n",
      " [ 3224    50]]\n",
      "0.755 (+/- 0.015) for {'C': 1, 'penalty': 'l1'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.86      0.02      0.03      3274\n",
      "\n",
      "avg / total       0.85      0.84      0.77     20508\n",
      "\n",
      "[[17226     8]\n",
      " [ 3224    50]]\n",
      "0.805 (+/- 0.052) for {'C': 1, 'penalty': 'l2'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.86      0.02      0.03      3274\n",
      "\n",
      "avg / total       0.85      0.84      0.77     20508\n",
      "\n",
      "[[17226     8]\n",
      " [ 3224    50]]\n",
      "0.753 (+/- 0.014) for {'C': 10, 'penalty': 'l1'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.86      0.02      0.03      3274\n",
      "\n",
      "avg / total       0.85      0.84      0.77     20508\n",
      "\n",
      "[[17226     8]\n",
      " [ 3224    50]]\n",
      "0.805 (+/- 0.052) for {'C': 10, 'penalty': 'l2'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.86      0.02      0.03      3274\n",
      "\n",
      "avg / total       0.85      0.84      0.77     20508\n",
      "\n",
      "[[17226     8]\n",
      " [ 3224    50]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=100, p=2,\n",
      "           weights='distance')\n",
      "0.591 (+/- 0.093) for {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.64      0.00      0.01      3274\n",
      "\n",
      "avg / total       0.81      0.84      0.77     20508\n",
      "\n",
      "[[17225     9]\n",
      " [ 3258    16]]\n",
      "0.333 (+/- 0.211) for {'algorithm': 'auto', 'n_neighbors': 10000, 'weights': 'distance'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.64      0.00      0.01      3274\n",
      "\n",
      "avg / total       0.81      0.84      0.77     20508\n",
      "\n",
      "[[17225     9]\n",
      " [ 3258    16]]\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
      "            max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "0.685 (+/- 0.007) for {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 2}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "0.685 (+/- 0.007) for {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "0.663 (+/- 0.012) for {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "0.695 (+/- 0.009) for {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "0.656 (+/- 0.012) for {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "0.692 (+/- 0.009) for {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "0.426 (+/- 0.007) for {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 2}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "0.456 (+/- 0.007) for {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "0.420 (+/- 0.010) for {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "0.471 (+/- 0.006) for {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "0.428 (+/- 0.008) for {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "0.478 (+/- 0.008) for {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.69      0.36      0.47      3274\n",
      "\n",
      "avg / total       0.86      0.87      0.85     20508\n",
      "\n",
      "[[16708   526]\n",
      " [ 2098  1176]]\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10000, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.732 (+/- 0.005) for {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.736 (+/- 0.005) for {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 10000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.732 (+/- 0.005) for {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.737 (+/- 0.006) for {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 10000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.735 (+/- 0.005) for {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.737 (+/- 0.005) for {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 10000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.729 (+/- 0.003) for {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.736 (+/- 0.005) for {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.666 (+/- 0.006) for {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.676 (+/- 0.008) for {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 10000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.690 (+/- 0.010) for {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.686 (+/- 0.011) for {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 10000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.670 (+/- 0.007) for {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.676 (+/- 0.008) for {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 10000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.686 (+/- 0.009) for {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "0.688 (+/- 0.011) for {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     17234\n",
      "          1       0.73      0.37      0.50      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.86     20508\n",
      "\n",
      "[[16790   444]\n",
      " [ 2049  1225]]\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=2, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False)\n",
      "0.845 (+/- 0.047) for {'max_features': 2, 'n_estimators': 100}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92     17234\n",
      "          1       0.88      0.04      0.08      3274\n",
      "\n",
      "avg / total       0.85      0.85      0.78     20508\n",
      "\n",
      "[[17215    19]\n",
      " [ 3139   135]]\n",
      "0.827 (+/- 0.023) for {'max_features': 2, 'n_estimators': 10000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92     17234\n",
      "          1       0.88      0.04      0.08      3274\n",
      "\n",
      "avg / total       0.85      0.85      0.78     20508\n",
      "\n",
      "[[17215    19]\n",
      " [ 3139   135]]\n",
      "0.664 (+/- 0.008) for {'max_features': 10, 'n_estimators': 100}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92     17234\n",
      "          1       0.88      0.04      0.08      3274\n",
      "\n",
      "avg / total       0.85      0.85      0.78     20508\n",
      "\n",
      "[[17215    19]\n",
      " [ 3139   135]]\n",
      "0.673 (+/- 0.007) for {'max_features': 10, 'n_estimators': 10000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92     17234\n",
      "          1       0.88      0.04      0.08      3274\n",
      "\n",
      "avg / total       0.85      0.85      0.78     20508\n",
      "\n",
      "[[17215    19]\n",
      " [ 3139   135]]\n",
      "AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1.0,\n",
      "          n_estimators=10000, random_state=None)\n",
      "0.698 (+/- 0.004) for {'algorithm': 'SAMME', 'n_estimators': 1000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93     17234\n",
      "          1       0.71      0.42      0.53      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.87     20508\n",
      "\n",
      "[[16664   570]\n",
      " [ 1899  1375]]\n",
      "0.698 (+/- 0.006) for {'algorithm': 'SAMME', 'n_estimators': 10000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93     17234\n",
      "          1       0.71      0.42      0.53      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.87     20508\n",
      "\n",
      "[[16664   570]\n",
      " [ 1899  1375]]\n",
      "0.690 (+/- 0.006) for {'algorithm': 'SAMME.R', 'n_estimators': 1000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93     17234\n",
      "          1       0.71      0.42      0.53      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.87     20508\n",
      "\n",
      "[[16664   570]\n",
      " [ 1899  1375]]\n",
      "0.665 (+/- 0.004) for {'algorithm': 'SAMME.R', 'n_estimators': 10000}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93     17234\n",
      "          1       0.71      0.42      0.53      3274\n",
      "\n",
      "avg / total       0.87      0.88      0.87     20508\n",
      "\n",
      "[[16664   570]\n",
      " [ 1899  1375]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.000 (+/- 0.000) for {'C': 0.01, 'kernel': 'rbf'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.23      0.00      0.00      3274\n",
      "\n",
      "avg / total       0.74      0.84      0.77     20508\n",
      "\n",
      "[[17207    27]\n",
      " [ 3266     8]]\n",
      "0.000 (+/- 0.000) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.23      0.00      0.00      3274\n",
      "\n",
      "avg / total       0.74      0.84      0.77     20508\n",
      "\n",
      "[[17207    27]\n",
      " [ 3266     8]]\n",
      "0.214 (+/- 0.049) for {'C': 1, 'kernel': 'rbf'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.23      0.00      0.00      3274\n",
      "\n",
      "avg / total       0.74      0.84      0.77     20508\n",
      "\n",
      "[[17207    27]\n",
      " [ 3266     8]]\n",
      "0.212 (+/- 0.017) for {'C': 10, 'kernel': 'rbf'}\n",
      "baseline: 0.15964501657889604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91     17234\n",
      "          1       0.23      0.00      0.00      3274\n",
      "\n",
      "avg / total       0.74      0.84      0.77     20508\n",
      "\n",
      "[[17207    27]\n",
      " [ 3266     8]]\n"
     ]
    }
   ],
   "source": [
    "for clf in clfs:\n",
    "    grid_clf = GridSearchCV(clf, small_grid[clf], cv=5, scoring=score, n_jobs=-1)\n",
    "    grid_clf.fit(x_train, y_train)\n",
    "\n",
    "    print(grid_clf.best_estimator_)\n",
    "\n",
    "    for params, mean_score, all_scores in grid_clf.grid_scores_:\n",
    "        print(\"{:.3f} (+/- {:.3f}) for {}\".format(\n",
    "            mean_score, all_scores.std() / 2, params))\n",
    "        y_true, y_pred = y_test, grid_clf.predict(x_test)\n",
    "        print('baseline:', y_true.mean())\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
